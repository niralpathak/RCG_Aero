{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing with Python\n",
    "Part of the SWEET Workshop series presented by the [IDEA Student Center at UC San Diego](http://idea.ucsd.edu/).\n",
    "\n",
    "### Goals\n",
    "Learn the basics of image processing using Python, including:\n",
    "- importing images\n",
    "- displaying images\n",
    "- cropping images\n",
    "- indexing images (grayscale and color)\n",
    "- filtering images\n",
    "\n",
    "### Requirements\n",
    "- python 2.7\n",
    "- ipython-notebook\n",
    "- numpy\n",
    "- matplotlib\n",
    "- scipy\n",
    "- pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to load the required packages\n",
    "#\n",
    "# NOTE: recall that in the Intro to Python workshop we learned\n",
    "# that you can assign aliases to package names so you don't\n",
    "# have to type as much (e.g. \"np\" for \"numpy\")\n",
    "#\n",
    "\n",
    "# numpy for vector operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scipy.ndimage for importing images\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the packages are loaded, we can import our\n",
    "# first image\n",
    "\n",
    "# a gray-scale image from NOAA's GOES-WEST geosynchronous\n",
    "# satellite\n",
    "#\n",
    "# you can view more images here: http://www.wrh.noaa.gov/satellite/?wfo=sgx\n",
    "#\n",
    "image_filename = \"satellite.png\"\n",
    "\n",
    "# load the image\n",
    "image = ndimage.imread(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `ndimage.imread()` loads the image as a numpy array,\n",
    "# so we can check the image dimensions with numpy's\n",
    "# `shape()` function\n",
    "print np.shape(image)\n",
    "\n",
    "# NOTE: you can also call `shape` from the array\n",
    "# directly\n",
    "#print image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can display the images using matplotlib\n",
    "plt.imshow(image)\n",
    "\n",
    "# notice that even though the image is grayscale,\n",
    "# `imshow()` adds a colormap (which denotes the\n",
    "# pixel intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try displaying the image with a different colormap\n",
    "# \n",
    "# usage:\n",
    "#     plt.imshow(image, cmap=\"some_colormap\")\n",
    "#\n",
    "# example colormaps:\n",
    "# - \"Greys\"\n",
    "# - \"Blues\"\n",
    "# - \"cubehelix\"\n",
    "#\n",
    "# NOTE: you can also display the reverse of the colormap\n",
    "# by appending \"_r\" to the end of the name (e.g. \"Greys_r\")\n",
    "#\n",
    "# for more colormaps, see the matplotlib website:\n",
    "#\n",
    "#    http://matplotlib.org/users/colormaps.html\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the image is just a numpy array, we can use\n",
    "# indexing to select specific portions of the image,\n",
    "# thereby cropping the image\n",
    "\n",
    "# select the first 100 rows and first 100 columns\n",
    "plt.imshow(image[:100, :100], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that we index relative to the top left corner, which\n",
    "# is consistent with other image processing packages in Python\n",
    "# (and other languages, e.g., C++)\n",
    "\n",
    "# but we can easily select portions of the image relative to the\n",
    "# bottom and right by using numpy's negative index syntax\n",
    "\n",
    "# display the last 200 rows and last 100 columns (the 200x100 pixels \n",
    "# in the bottom right of the original image)\n",
    "plt.imshow(image[-200:, -100:], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try display other regions of the image (e.g. the 100x100 pixels\n",
    "# in the top right of the image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Displaying color images\n",
    "Let's move onto color images, which besides from being more \n",
    "interesting to look at, can also provide additional useful \n",
    "information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and displaying color images works similarly to\n",
    "# grayscale images\n",
    "\n",
    "# an image of a Husky from r/aww\n",
    "#\n",
    "# source: /u/rickydlam\n",
    "#     https://www.reddit.com/r/aww/comments/1lompf/reddit_maya_maya_derp_mayas_my_roommates_dog_but/\n",
    "#\n",
    "dog = ndimage.imread(\"husky.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many dimensions does the color image have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can display the color image the same way as the grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the image was displayed in full color, instead of\n",
    "# with a colormap (as with the grayscale image)\n",
    "#\n",
    "# this is because the grayscale image only had pixel intensities\n",
    "# for one color channel (the gray channel), while the color image\n",
    "# has three color channels (red, green, blue) and so matplotlib\n",
    "# is able to display the \"real\" colors of the image (instead of\n",
    "# just the pixel intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the color image is also just a numpy array, we can use\n",
    "# indexing to select only the red color channel\n",
    "\n",
    "# all rows, all columns, but only the first layer (i.e. the red\n",
    "# color channel)\n",
    "dog_red = dog[:, :, 0]\n",
    "\n",
    "\n",
    "# we can add a colorbar (to reference which color means which\n",
    "# value) using `plt.colorbar()`\n",
    "\n",
    "\n",
    "# notice anything about the range of values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try displaying the green channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the blue channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try another image that has more a clear color\n",
    "# contrast/segmentation\n",
    "\n",
    "# a photo of a sensor (black) with an aluminum base (silver)\n",
    "# and a sensor cap (red)\n",
    "sensor_filename = \"sensor.jpg\"\n",
    "\n",
    "# load the image\n",
    "\n",
    "\n",
    "# and display it (in full color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now display only the red color channel\n",
    "\n",
    "\n",
    "# notice anything about the red cap?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filters\n",
    "Since an image is just a signal, we can apply filters (e.g. to\n",
    "remove \"noise\"). Aside from filtering to remove \"bad\" data, we\n",
    "can also apply filters to extract useful data.\n",
    "\n",
    "For example, let's try applying a filter to \"detect\" edges in\n",
    "an image (or at least make the edges more prominent). More\n",
    "specifically, let's apply a Sobel filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll load an image, but use `flatten=True` to make it\n",
    "# grayscale\n",
    "source_image = ndimage.imread(\"sensor.jpg\", flatten=True)\n",
    "\n",
    "# display the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new we need to apply the Sobel filter along the x and y axes\n",
    "\n",
    "# x-axis\n",
    "sobel_x = ndimage.filters.sobel(source_image, axis=0, mode='constant')\n",
    "\n",
    "# y-axis\n",
    "sobel_y = ndimage.filters.sobel(source_image, axis=1, mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we'll calculate the magnitude of the x and y-axis filters\n",
    "# (which will be our final filtered image)\n",
    "filtered_image = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "\n",
    "# notice anything about the above calculation? perhaps\n",
    "# it reminds you of a very common math equation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the filtered image\n",
    "\n",
    "\n",
    "# notice how almost everything is black, except\n",
    "# for the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make things easier, let's display the two images side-by-side\n",
    "\n",
    "# create a subplot:\n",
    "# - 1 row\n",
    "# - 2 columns\n",
    "# - first index\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.imshow(source_image, cmap='Greys_r')\n",
    "\n",
    "plt.title(\"Source image\")\n",
    "\n",
    "# create the second subplot:\n",
    "# - 1 row\n",
    "# - 2 columns\n",
    "# - second index\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.imshow(filtered_image, cmap='Greys_r')\n",
    "\n",
    "plt.title(\"Filtered image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now go back and try to apply this edge detection filter\n",
    "# to other methods (e.g. the photo of the Husky)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
